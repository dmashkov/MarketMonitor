# ğŸ—ï¸ PHASE 4: MULTI-AGENT PIPELINE ARCHITECTURE

**Version:** 1.0.0
**Date:** 2025-12-14
**Status:** Architecture Design Complete âœ…
**Target:** Phase 4 Part 4-8 Implementation

---

## ğŸ“Š EXECUTIVE SUMMARY

**Goal:** Replace single monolithic ai-search with modular multi-agent sequential pipeline.

**Pipeline Type:** Sequential (not parallel) for MVP
**Key Decision:** Raw â†’ Normalized â†’ Canonical data transformation
**Core Concept:** Monitoring Profiles replace generic Prompts Library

---

## ğŸ”„ DATA FLOW OVERVIEW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 4 MVP PIPELINE ARCHITECTURE                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[ADMIN TRIGGER]
  â†“
Admin Panel â†’ "ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Pipeline" tab â†’ Select monitoring_profile â†’ RUN
  â†“
[SEARCH-ORCHESTRATOR] (Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Edge Function)
  â”‚
  â”œâ”€ Create search_run record (status: 'running')
  â”‚
  â”œâ”€ Step 1: SOURCE HUNTER
  â”‚  â”œâ”€ Load monitoring_profile
  â”‚  â”œâ”€ Get available sources (by segments, geographies)
  â”‚  â”œâ”€ Generate search queries (OpenAI gpt-4o-mini)
  â”‚  â”œâ”€ Find URLs (MOCK for MVP)
  â”‚  â””â”€ INSERT documents (RAW layer)
  â”‚     â””â”€ Stores: title, source_url, source_id, document_type='webpage'
  â”‚
  â”œâ”€ Step 2: CONTENT FETCHER
  â”‚  â”œâ”€ GET each URL (timeout: 10s, retries: 3)
  â”‚  â”œâ”€ Parse HTML â†’ extract text (max 5000 chars)
  â”‚  â”œâ”€ Extract published_date from meta tags
  â”‚  â”œâ”€ Handle errors: log and continue
  â”‚  â””â”€ UPDATE documents.content_text + published_date
  â”‚
  â”œâ”€ Step 3: DOCUMENT PROCESSOR (ONE LLM call per document)
  â”‚  â”œâ”€ Read: documents.content_text
  â”‚  â”œâ”€ Call GPT-4o: classify segment, event_types, brands, geographies
  â”‚  â”œâ”€ Parse JSON response
  â”‚  â”œâ”€ INSERT INTO:
  â”‚  â”‚  â”œâ”€ document_segments
  â”‚  â”‚  â”œâ”€ document_event_types
  â”‚  â”‚  â”œâ”€ document_brands
  â”‚  â”‚  â””â”€ document_geographies
  â”‚  â”œâ”€ Generate embeddings (OpenAI text-embedding-3-small)
  â”‚  â”œâ”€ Clean content_text (canonical layer)
  â”‚  â””â”€ UPDATE documents.embedding, documents.content_text
  â”‚
  â”œâ”€ Step 4: DEDUP AGENT
  â”‚  â”œâ”€ Compare embeddings (cosine similarity)
  â”‚  â”œâ”€ Mark duplicates: UPDATE documents.is_duplicate = TRUE
  â”‚  â””â”€ Continue pipeline for ALL documents (even duplicates)
  â”‚
  â”œâ”€ Step 5: CRITICALITY SCORER
  â”‚  â”œâ”€ Read: documents (with context from relations)
  â”‚  â”œâ”€ Call GPT-4o: score 1-5
  â”‚  â””â”€ UPDATE documents.criticality_level
  â”‚
  â”œâ”€ Step 6: EVENT EXTRACTOR
  â”‚  â”œâ”€ For each document:
  â”‚  â”‚  â”œâ”€ Call GPT-4o: extract structured event
  â”‚  â”‚  â”œâ”€ Can create 0-N events per document
  â”‚  â”‚  â””â”€ INSERT INTO events
  â”‚  â”œâ”€ Link: events.document_id = documents.id
  â”‚  â””â”€ Set: events.source_type = 'source_hunter'
  â”‚
  â”œâ”€ Update search_run:
  â”‚  â”œâ”€ status: 'completed'
  â”‚  â”œâ”€ documents_created: N
  â”‚  â”œâ”€ events_created: M
  â”‚  â””â”€ completed_at: NOW()
  â”‚
  â””â”€ Return response to Admin Panel
     â””â”€ Display: summary, progress, any errors


[PARALLEL TRACK - NOT IN MVP]
ai-search remains independent:
  Admin/User â†’ Dashboard â†’ "Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ AI ĞŸĞ¾Ğ¸ÑĞº"
  â†’ ai-search (GPT-4o web_search)
  â†’ INSERT events (source_type='ai_search')

  DECISION: Later (Phase 4 Part 7+) we'll unify both into one orchestrator
```

---

## ğŸ“‹ KEY ARCHITECTURAL DECISIONS

### **1. TWO INDEPENDENT SEARCH PATHS (MVP)**

| Path | Trigger | Speed | Coverage | Events Created |
|------|---------|-------|----------|-----------------|
| **ai-search** | User Dashboard | Fast (30s) | Web search only | source_type='ai_search' |
| **source-hunter pipeline** | Admin (Monitoring Profile) | Slow (5-10min) | Full pipeline | source_type='source_hunter' |

**Decision:** Keep separate on MVP. Unify in Phase 4 Part 7.
**Rationale:** Different UX/requirements, easier to develop separately first.

---

### **2. DATA LAYERS: RAW â†’ NORMALIZED â†’ CANONICAL**

```
RAW LAYER (Source Hunter + Content Fetcher):
â”œâ”€ content_text: filled (first 5000 chars from HTML)
â”œâ”€ published_date: filled (from HTML meta tags)
â”œâ”€ All taxonomies: NULL
â””â”€ embedding: NULL

NORMALIZED LAYER (Document Processor):
â”œâ”€ content_text: same (not yet cleaned)
â”œâ”€ segment_ids, event_type_ids, brand_ids, geography_ids: FILLED
â”œâ”€ embedding: FILLED
â””â”€ criticality_level: NULL

CANONICAL LAYER (ready for consumption):
â”œâ”€ content_text: CLEANED (standardized, no extra whitespace)
â”œâ”€ All fields: FILLED and validated
â”œâ”€ embedding: INDEXED
â””â”€ is_duplicate: MARKED
```

**Benefits:**
- Keep raw data for audit trail
- Understand transformation at each stage
- Easier debugging and reprocessing
- Compliance/archival if needed

---

### **3. SOFT DELETE FOR DUPLICATES**

**Decision:** is_duplicate=TRUE (soft delete), NOT hard DELETE

```
documents {
  id, title, content_text,
  is_duplicate: boolean
}

Benefits:
- Keep audit trail of duplicates
- Can trace duplicate relationships
- Reversible if dedup logic wrong
- Still create events from duplicates (for completeness)
```

---

### **4. MANY-TO-MANY: SEPARATE TABLES**

**Decision:** Separate linking tables, NOT ARRAY columns

```sql
documents { id, title, ... }
document_brands { document_id, brand_id } -- PK
document_segments { document_id, segment_id } -- PK
document_geographies { document_id, geography_id } -- PK
document_event_types { document_id, event_type_id } -- PK
```

**Benefits:**
- Proper DB normalization
- Can add metadata (confidence, source, etc.)
- Easy indexing and querying
- Referential integrity via FK

---

### **5. MONITORING PROFILES: Configuration as Code**

**Decision:** Profiles determine scope and behavior, not individual prompts

```
monitoring_profiles (replaces generic prompts):
â”œâ”€ name: "RAC Retail Promo"
â”œâ”€ scope: segment_ids[], brand_ids[], geography_ids[], event_type_ids[]
â”œâ”€ execution: priority, max_sources_per_run
â”œâ”€ quality_gates: dedupe_threshold
â””â”€ prompts: prompt_template_id (ÑÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½)

BENEFITS:
- Admin manages profiles, not individual prompts
- Each profile has consistent behavior
- Easy to enable/disable entire monitoring strategy
- Promotes reusability of prompts
```

---

### **6. PROMPT TEMPLATES: Versioning + Parameterization**

**Decision:** Prompts as templates with placeholders, stored in DB

```sql
prompt_templates {
  id, name, stage ('search'|'classify'|'score'),
  template_text: "Analyze {segment} market. Classify event_types from: {event_types}..."
  is_active: boolean
}

search_runs_prompts {
  search_run_id, stage_name, prompt_template_id,
  actual_prompt_text: (fully rendered prompt sent to LLM)
}
```

**Benefits:**
- Track which exact prompt was used
- A/B test different prompts
- Edit prompts in UI (later)
- Audit trail of changes

---

### **7. SEQUENTIAL PIPELINE (not Parallel)**

**Decision:** await each step before moving to next

```typescript
await sourceHunter()        // returns document_ids[]
await contentFetcher()      // returns updated document_ids[]
await documentProcessor()   // returns processed document_ids[]
await dedupAgent()          // returns with is_duplicate marked
await criticalityScorer()   // returns scored document_ids[]
await eventExtractor()      // returns event_ids[] created
```

**Benefits on MVP:**
- Simple to debug
- Clear error handling
- Easy to understand flow
- No race conditions

**Future:** Parallel with orchestrator (Phase 5)

---

### **8. ONE LLM CALL PER DOCUMENT (Document Processor)**

**Decision:** Single prompt for classification + extraction

```
One LLM call (gpt-4o):
Input: document.content_text
Output JSON: {
  segment_id: UUID,
  event_type_ids: [UUID],
  brand_ids: [UUID],
  geography_ids: [UUID]
}
```

**Benefits:**
- Cost efficient
- Faster execution
- Simpler prompt engineering
- Less API calls

**Trade-off:** Less specialized for each task (OK for MVP)

---

### **9. EVENTS FROM DOCUMENTS (Event Extractor)**

**Decision:** One document can create 0-N events

```
Event Extractor (VĞĞ Ğ˜ĞĞĞ¢ A):
for each document (where is_duplicate=FALSE):
  call LLM: "Extract events from this document"
  â†’ can return 0, 1, 2, or more events
  â†’ INSERT INTO events

IMPORTANT: Even create events from duplicates
(for comprehensive search results)
```

**Benefits:**
- More flexible event modeling
- Don't lose information from duplicate-marked documents
- Natural mapping: doc â†’ events

---

### **10. CRITICALITY SCORER: Work on Events**

**Decision:** Score AFTER event creation (VARIANT B)

```
Timeline:
1. Document Processor: fills taxonomies
2. Dedup Agent: marks is_duplicate
3. Criticality Scorer: WORKS ON DOCUMENTS (scores documents)
4. Event Extractor: creates events, inherits document.criticality_level
5. Events table: shows criticality
```

**Benefits:**
- Score is based on document context (not just extracted event)
- Unified scoring logic
- Can rescore documents later if needed

---

## ğŸ—„ï¸ DATABASE SCHEMA OVERVIEW

See separate **DATABASE_SCHEMA.md** for full details.

**New/Modified Tables:**
- âœ… documents (UPDATE: remove ARRAY columns)
- âœ… document_brands, document_segments, document_geographies, document_event_types (CREATE)
- âœ… event_types (CREATE new)
- âœ… search_runs (UPDATE)
- âœ… search_runs_stages (CREATE)
- âœ… search_runs_prompts (CREATE)
- âœ… monitoring_profiles (CREATE)
- âœ… prompt_templates (CREATE)
- âœ… events (UPDATE: add source_type, document_id)

---

## ğŸ¤– AGENTS SPECIFICATION

See separate **AGENT_SPECS.md** for detailed specifications per agent.

**Sequential Order:**
1. Source Hunter (finds URLs)
2. Content Fetcher (downloads content)
3. Document Processor (classifies + embeddings)
4. Dedup Agent (marks duplicates)
5. Criticality Scorer (rates importance)
6. Event Extractor (creates events)

---

## ğŸ¯ MONITORING PROFILES (Configuration)

### Purpose
Replace "generic prompts library" with "targeted monitoring strategies"

### Example Profiles (for future)
- RAC Retail Promo (discounts on consumer units)
- RAC Marketplaces (Ozon/WB price changes)
- VRF Tenders (B2B projects)
- Distributors Programs (dealer incentives)
- Brand Launches (new products)

### MVP: Single Generic Profile
On MVP, we'll create ONE profile for testing:
```sql
INSERT INTO monitoring_profiles (
  name='MVP Test Profile',
  segment_ids=[all segments],
  event_type_ids=[all event types],
  priority=5,
  prompt_template_id=[search template]
)
```

---

## ğŸš€ EXECUTION FLOW: MVP

### User Interaction
```
Admin Panel (NEW TAB: "ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Pipeline")
â”œâ”€ Dropdown: Select monitoring_profile
â”œâ”€ Button: "Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ"
â””â”€ Displays:
   â”œâ”€ Progress: "Running Source Hunter... (5 docs found)"
   â”œâ”€ Progress: "Fetching content... (5 docs)"
   â”œâ”€ Progress: "Processing... (3 processed, 2 errored)"
   â”œâ”€ Final Results:
   â”‚  â”œâ”€ Documents created: 5
   â”‚  â”œâ”€ Duplicates found: 1
   â”‚  â”œâ”€ Events created: 12
   â”‚  â”œâ”€ Execution time: 4m 23s
   â”‚  â””â”€ Errors: 0
```

### Backend: Search Orchestrator
```
POST /functions/v1/search-orchestrator
â”œâ”€ Body: { monitoring_profile_id: UUID }
â”œâ”€ Response: {
â”‚    search_run_id: UUID,
â”‚    status: 'running',
â”‚    message: 'Pipeline started'
â”‚  }
â””â”€ Streams progress via WebSocket or polling
```

---

## ğŸ“Š SEARCH_RUNS TRACKING

```sql
search_runs {
  id, type ('ai_search'|'source_hunter'), status,
  monitoring_profile_id (nullable),
  documents_created, events_created,
  started_at, completed_at, execution_time_ms,
  error_message (nullable), created_by
}

search_runs_stages {
  id, search_run_id, stage_name,
  status, documents_processed,
  started_at, completed_at, error_message
}

search_runs_prompts {
  id, search_run_id, stage_name, prompt_template_id,
  actual_prompt_text (for A/B testing & audit)
}
```

---

## ğŸ”„ FUTURE ROADMAP

### Phase 4 Part 7: Search Orchestrator Unification
- Create unified orchestrator that handles both ai-search and source-hunter
- Merge events into single stream

### Phase 5: Scheduling + Parallel Execution
- Add CRON scheduling to monitoring_profiles
- Implement true parallel agent execution
- Add Alert Manager and Report Generator agents

### Phase 6: Advanced Features
- Prompt versioning with history
- A/B testing framework
- Quality metrics dashboard
- Custom profile builder UI

---

## âœ… DECISION MATRIX

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Search Paths | 2 independent | Keep MVP simple, unify later |
| Data Layers | RAWâ†’NORMâ†’CAN | Audit trail, easier debugging |
| Duplicates | Soft delete | Keep history, still create events |
| Relations | Separate tables | DB normalization, integrity |
| Profiles | Config-first | Admin-friendly, reusable |
| Prompts | Templates+Params | A/B test, audit, editable |
| Pipeline | Sequential | Simple, clear, debuggable |
| LLM Calls | 1 per doc (Processor) | Cost efficient |
| Events | From docs (0-N) | Flexible, don't lose data |
| Scoring | On events | After extraction |

---

## ğŸ“š Related Documents

- **DATABASE_SCHEMA.md** â€” Full SQL schema
- **AGENT_SPECS.md** â€” Each agent detailed spec
- **API_CONTRACTS.md** â€” Edge Function interfaces
- **PHASE_4_ROADMAP.md** â€” Implementation timeline
- **DEVELOPMENT_STATUS.md** â€” Current progress

---

**Next Step:** Implement migrations, then start agents in order.
