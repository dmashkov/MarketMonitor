/**
 * Source Hunter Agent
 *
 * –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ Perplexity AI
 * - –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
 * - –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç search queries —á–µ—Ä–µ–∑ OpenAI (gpt-4o-mini)
 * - –í—ã–ø–æ–ª–Ω—è–µ—Ç –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Perplexity API —Å web search
 * - –°–æ–∑–¥–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ë–î —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ URLs
 * - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ URLs –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Content Fetcher
 * - Rate limiting: 1000 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å MAX (–∑–∞—â–∏—Ç–∞ –æ—Ç –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞)
 */

import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.47.0';
import { SourceHunterRequest, SourceHunterResponse, SearchSource, SearchResult } from './types.ts';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// Initialize Supabase client
const supabaseUrl = Deno.env.get('SUPABASE_URL');
const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');

if (!supabaseUrl || !supabaseServiceKey) {
  throw new Error('Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY');
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

// ============================================================================
// Helpers
// ============================================================================

/**
 * –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
 */
async function getSearchSources(
  segment_ids?: string[],
  geography_ids?: string[]
): Promise<SearchSource[]> {
  try {
    let query = supabase
      .from('sources')
      .select('id, name, source_type_id, website_url, telegram_channel, priority')
      .eq('is_active', true);

    // NOTE: source_segments and source_geographies tables don't exist in current schema
    // For now, ignore segment and geography filters and return all active sources
    // TODO: Create source_segments and source_geographies tables in future migration

    // –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã —Å–µ–≥–º–µ–Ω—Ç—ã, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å–≤—è–∑–∏ source_segments
    // Currently disabled: source_segments table doesn't exist
    // if (segment_ids && segment_ids.length > 0) {
    //   const { data: sourceIds } = await supabase
    //     .from('source_segments')
    //     .select('source_id')
    //     .in('segment_id', segment_ids);
    //
    //   if (sourceIds && sourceIds.length > 0) {
    //     const ids = sourceIds.map((x) => x.source_id);
    //     query = query.in('id', ids);
    //   }
    // }

    // –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –≥–µ–æ–≥—Ä–∞—Ñ–∏—è, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å–≤—è–∑–∏ source_geographies
    // Currently disabled: source_geographies table doesn't exist
    // if (geography_ids && geography_ids.length > 0) {
    //   const { data: sourceIds } = await supabase
    //     .from('source_geographies')
    //     .select('source_id')
    //     .in('geography_id', geography_ids);
    //
    //   if (sourceIds && sourceIds.length > 0) {
    //     const ids = sourceIds.map((x) => x.source_id);
    //     query = query.in('id', ids);
    //   }
    // }

    const { data, error } = await query.order('priority', { ascending: false });

    if (error) {
      console.error('Error fetching sources:', error);
      return [];
    }

    return (data as SearchSource[]) || [];
  } catch (error) {
    console.error('Error getting search sources:', error);
    return [];
  }
}

/**
 * –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å search queries –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —á–µ—Ä–µ–∑ OpenAI
 */
async function generateSearchQueries(prompt: string, sources: SearchSource[]): Promise<Map<string, string>> {
  const openaiKey = Deno.env.get('OPENAI_API_KEY');
  if (!openaiKey) {
    throw new Error('Missing OPENAI_API_KEY');
  }

  const sourceNames = sources.map((s) => s.name).join(', ');

  const systemPrompt = `–í—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ search queries –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –Ω–∞ –∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä—ã–Ω–∫–µ –†–æ—Å—Å–∏–∏.

–í–∞–º –¥–∞–Ω—ã:
1. –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

–í–∞—à–∞ –∑–∞–¥–∞—á–∞: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π search query.

–ü—Ä–∞–≤–∏–ª–∞:
- Queries –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –í–∫–ª—é—á–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
- –ë—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ (–Ω–µ –æ–±—â–∏–µ)

–û—Ç–≤–µ—Ç: JSON –æ–±—ä–µ–∫—Ç {
  "source_name_1": "search query 1",
  "source_name_2": "search query 2"
}`;

  const userPrompt = `–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–º–ø—Ç: "${prompt}"

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: ${sourceNames}

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ search queries –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${openaiKey}`,
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.7,
        max_tokens: 1000,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.statusText}`);
    }

    const data = await response.json();
    const content = data.choices[0].message.content;

    // Parse JSON response
    const jsonMatch = content.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid JSON in OpenAI response');
    }

    const queries = JSON.parse(jsonMatch[0]);
    const result = new Map<string, string>();

    sources.forEach((source) => {
      const query = queries[source.name];
      if (query) {
        result.set(source.id, query);
      }
    });

    return result;
  } catch (error) {
    console.error('Error generating search queries:', error);
    throw error;
  }
}

/**
 * –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–º–∏—Ç Perplexity API (1000 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å)
 */
async function canMakePerplexitySearch(): Promise<boolean> {
  try {
    const { data, error } = await supabase.rpc('can_make_perplexity_search');

    if (error) {
      console.error('Error checking Perplexity limit:', error);
      return false;
    }

    return data === true;
  } catch (error) {
    console.error('Failed to check Perplexity limit:', error);
    return false;
  }
}

/**
 * –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Perplexity API
 */
async function incrementPerplexityUsage(): Promise<number> {
  try {
    const { data, error } = await supabase.rpc('increment_perplexity_usage');

    if (error) {
      console.error('Error incrementing Perplexity usage:', error);
      return 0;
    }

    return data || 0;
  } catch (error) {
    console.error('Failed to increment Perplexity usage:', error);
    return 0;
  }
}

/**
 * –í—ã–ø–æ–ª–Ω–∏—Ç—å –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Perplexity API
 */
async function searchDocuments(query: string, source: SearchSource): Promise<SearchResult[]> {
  const perplexityApiKey = Deno.env.get('PERPLEXITY_API_KEY');

  if (!perplexityApiKey) {
    throw new Error('Missing PERPLEXITY_API_KEY environment variable');
  }

  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
  const canSearch = await canMakePerplexitySearch();
  if (!canSearch) {
    console.warn(`‚ö†Ô∏è Perplexity API daily limit reached (1000/1000). Skipping search for ${source.name}`);
    return [];
  }

  // –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
  const searchPrompt = `
Search for: ${query}

Focus on content from: ${source.website_url || source.name}
${source.telegram_channel ? `Also check Telegram channel: ${source.telegram_channel}` : ''}

Find recent news, articles, or announcements related to HVAC equipment, climate control, and air conditioning market in Russia.

Return only real, verifiable sources with actual URLs.
  `.trim();

  console.log(`üîç Searching via Perplexity API: "${query}" for ${source.name}`);

  try {
    const response = await fetch('https://api.perplexity.ai/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${perplexityApiKey}`,
      },
      body: JSON.stringify({
        model: 'sonar',
        messages: [
          {
            role: 'system',
            content: 'You are a helpful research assistant that finds recent news articles and returns structured data with real URLs.',
          },
          {
            role: 'user',
            content: searchPrompt,
          },
        ],
        temperature: 0.2,
        max_tokens: 1000,
        return_citations: true,
        search_recency_filter: 'week', // Last week only
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Perplexity API error (${response.status}): ${errorText}`);
    }

    const data = await response.json();

    // Increment usage counter
    const newCount = await incrementPerplexityUsage();
    console.log(`üìä Perplexity API usage: ${newCount}/1000 today`);

    // Extract citations (URLs) from Perplexity response
    const citations = data.citations || [];
    const message = data.choices?.[0]?.message?.content || '';

    console.log(`‚úÖ Perplexity found ${citations.length} citations for ${source.name}`);

    // üîç DETAILED LOGGING: Log full Perplexity response for debugging
    console.log('üìã PERPLEXITY RESPONSE DETAILS:');
    console.log(`   Source: ${source.name}`);
    console.log(`   Query: ${query}`);
    console.log(`   Model: sonar`);
    console.log(`   Citations count: ${citations.length}`);

    if (citations.length > 0) {
      console.log('   üìé Citations (URLs):');
      citations.forEach((url: string, idx: number) => {
        console.log(`      ${idx + 1}. ${url}`);
      });
    } else {
      console.warn('   ‚ö†Ô∏è NO CITATIONS returned by Perplexity!');
    }

    console.log(`   üìù Message preview: ${message.substring(0, 200)}...`);
    console.log(`   üîó Full response structure:`, JSON.stringify({
      choices_count: data.choices?.length || 0,
      citations_count: citations.length,
      has_message: !!message,
      model: data.model,
      usage: data.usage,
    }, null, 2));

    // Parse citations into SearchResults
    const results: SearchResult[] = citations.map((url: string, index: number) => {
      // Extract domain-specific title from the message or use generic
      const titleMatch = message.match(new RegExp(`([^.]+).*?${url.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')}`));
      const title = titleMatch?.[1]?.trim() || `${source.name} - Article ${index + 1}`;

      return {
        title: title.substring(0, 200), // Limit title length
        url: url,
        snippet: message.substring(0, 300), // First 300 chars as snippet
      };
    });

    return results;
  } catch (error) {
    console.error(`‚ùå Perplexity search failed for ${source.name}:`, error);
    throw error;
  }
}

/**
 * –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –ë–î
 */
async function saveDocument(
  title: string,
  url: string,
  sourceId: string,
  documentType: 'webpage' = 'webpage'
): Promise<string | null> {
  try {
    const { data, error } = await supabase.from('documents').insert({
      title,
      document_type: documentType,
      source_url: url,
      file_url: url,
      content_text: `–î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω —Å ${url}`,
      source_id: sourceId,
      published_date: new Date().toISOString(),
      fetched_at: new Date().toISOString(),
    }).select('id').single();

    if (error) {
      console.error('Error saving document:', error);
      return null;
    }

    return data?.id || null;
  } catch (error) {
    console.error('Error saving document:', error);
    return null;
  }
}

// ============================================================================
// Main Handler
// ============================================================================

async function handler(request: Request): Promise<Response> {
  // Handle CORS
  if (request.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  try {
    // Validate request
    if (request.method !== 'POST') {
      return new Response(
        JSON.stringify({ error: 'Method not allowed' }),
        {
          status: 405,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        }
      );
    }

    // Parse request body
    const requestData: SourceHunterRequest = await request.json();

    if (!requestData.prompt || requestData.prompt.trim().length === 0) {
      return new Response(
        JSON.stringify({
          status: 'error',
          documents_created: 0,
          urls: [],
          error: 'Missing required parameter: prompt',
        } as SourceHunterResponse),
        {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        }
      );
    }

    console.log('Starting Source Hunter Agent with prompt:', requestData.prompt);

    // Step 1: Get available sources
    const sources = await getSearchSources(
      requestData.segment_ids,
      requestData.geography_ids
    );

    if (sources.length === 0) {
      return new Response(
        JSON.stringify({
          status: 'error',
          documents_created: 0,
          urls: [],
          error: 'No sources found matching the filters',
        } as SourceHunterResponse),
        {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        }
      );
    }

    console.log(`Found ${sources.length} sources`);

    // Step 2: Generate search queries for each source
    const searchQueries = await generateSearchQueries(requestData.prompt, sources);
    console.log(`Generated ${searchQueries.size} search queries`);

    // Step 3: Search documents and save to DB
    const urls: string[] = [];
    const documentIds: string[] = [];
    let documentsCreated = 0;

    for (const source of sources) {
      const query = searchQueries.get(source.id);
      if (!query) {
        console.log(`No query generated for source: ${source.name}`);
        continue;
      }

      try {
        const results = await searchDocuments(query, source);

        for (const result of results) {
          const docId = await saveDocument(result.title, result.url, source.id);
          if (docId) {
            documentsCreated++;
            urls.push(result.url);
            documentIds.push(docId);
          }
        }
      } catch (error) {
        console.error(`Error searching source ${source.name}:`, error);
        continue;
      }
    }

    console.log(`Successfully created ${documentsCreated} documents`);

    // Return success response
    return new Response(
      JSON.stringify({
        status: 'success',
        documents_created: documentsCreated,
        document_ids: documentIds,
        urls,
        message: `Found and saved ${documentsCreated} documents`,
      } as SourceHunterResponse),
      {
        status: 200,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  } catch (error) {
    console.error('Source Hunter Agent error:', error);

    return new Response(
      JSON.stringify({
        status: 'error',
        documents_created: 0,
        urls: [],
        error: error instanceof Error ? error.message : 'Unknown error',
      } as SourceHunterResponse),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
}

Deno.serve(handler);
