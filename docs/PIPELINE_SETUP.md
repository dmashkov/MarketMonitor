# ğŸš€ Pipeline Setup & Execution Guide

**Date:** 2025-12-14
**Version:** 1.0.0
**Status:** Ready for testing

---

## ğŸ“‹ Prerequisites Checklist

Before running the pipeline, ensure all prerequisites are in place:

### Database Prerequisites

#### 1. Apply Migrations (001-018)

All migrations should be applied in this order:
- âœ… Migration 001: Initial schema (events, ai_prompts, search_runs, job_schedules)
- âœ… Migration 002: User profiles + auth triggers
- âœ… Migration 003: Job schedules
- âœ… Migration 004: RLS policies
- âœ… Migration 005: Sources and segments
- âœ… Migration 006: Seed sources, segments, brands, geographies
- âœ… Migration 007: Brands management
- âœ… Migration 008: Semantic search function
- âœ… Migration 009: Documents table
- âœ… Migration 010: Add file_size to documents
- ... (011-016)
- âœ… Migration 017: Phase 4 pipeline schema
- âœ… Migration 018: Phase 4 initial data (event_types, prompt_templates, monitoring_profiles)

**To check migration status:**
```bash
# In Supabase Dashboard â†’ SQL Editor
SELECT * FROM information_schema.tables WHERE table_schema = 'public' LIMIT 20;
```

#### 2. Verify Key Tables Exist

```sql
-- Run in Supabase SQL Editor
SELECT COUNT(*) as monitoring_profiles FROM public.monitoring_profiles;
SELECT COUNT(*) as prompt_templates FROM public.prompt_templates;
SELECT COUNT(*) as search_runs FROM public.search_runs;
SELECT COUNT(*) as sources FROM public.sources WHERE is_active = true;
```

Expected results:
- monitoring_profiles: >= 1
- prompt_templates: >= 1
- sources (active): >= 5

### Create Monitoring Profile (if not exists)

If monitoring_profiles is empty, run this SQL in Supabase Dashboard â†’ SQL Editor:

```sql
-- Get a prompt template ID (from Migration 018)
WITH template_id AS (
  SELECT id FROM public.prompt_templates
  WHERE stage = 'search'
  LIMIT 1
)
INSERT INTO public.monitoring_profiles (
  name,
  description,
  is_active,
  segment_ids,
  brand_ids,
  geography_ids,
  event_type_ids,
  priority,
  max_sources_per_run,
  dedupe_threshold,
  prompt_template_id
)
SELECT
  'MVP Test Profile - All Segments',
  'Test profile for pipeline execution',
  true,
  ARRAY(SELECT id FROM public.segments WHERE is_active = true LIMIT 8),
  ARRAY[]::UUID[],
  ARRAY(SELECT id FROM public.geographies WHERE is_active = true LIMIT 10),
  ARRAY(SELECT id FROM public.event_types WHERE is_active = true LIMIT 9),
  5,
  20,
  0.85,
  (SELECT id FROM template_id LIMIT 1)
WHERE NOT EXISTS (
  SELECT 1 FROM public.monitoring_profiles
  WHERE name = 'MVP Test Profile - All Segments'
);

-- Verify it was created
SELECT id, name, is_active, prompt_template_id FROM public.monitoring_profiles LIMIT 5;
```

---

## ğŸš€ Running the Pipeline

### Step 1: Start Frontend

```bash
cd frontend
npm install  # if needed
npm run dev
```

The frontend will start on `http://localhost:3005`

### Step 2: Navigate to Admin Panel

```
http://localhost:3005/admin
```

You should see tabs including:
- ğŸ·ï¸ Ğ‘Ñ€ĞµĞ½Ğ´Ñ‹
- ğŸ“„ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
- ğŸ“° Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸
- ğŸ‘¥ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ğ¸
- ğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹
- **ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Pipeline** â† Use this tab
- ğŸ“‹ Ğ›Ğ¾Ğ³Ğ¸ Pipeline â† Monitor here

### Step 3: Execute Pipeline

1. Click on **"ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº Pipeline"** tab
2. You should see a dropdown with monitoring profiles
3. Select **"MVP Test Profile - All Segments"**
4. Click **"Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Pipeline"** button

The system will:
- Create a `search_run` record
- Execute Source Hunter (searches for documents)
- Execute Content Fetcher (loads content from URLs)
- Execute Document Processor (classifies documents, generates embeddings)
- Display progress in real-time

### Step 4: Monitor Progress

The **PipelineProgress** component shows:
- Current stage (Source Hunter / Content Fetcher / Document Processor)
- Status (running/completed/failed)
- Number of documents processed
- Execution time

### Step 5: View Results

After completion, check:

#### In Admin Panel:
1. **"ğŸ“„ Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹"** tab - New documents should appear
2. **"ğŸ“‹ Ğ›Ğ¾Ğ³Ğ¸ Pipeline"** tab - Shows execution history with:
   - Status badges
   - Execution duration
   - Document count
   - Stage-by-stage progress
   - Error messages (if any)

#### In Supabase Dashboard:
1. **search_runs table**
   - New record with status = 'completed'
   - execution_time_ms shows duration
   - documents_created shows count

2. **search_runs_stages table**
   - 3 rows (source_hunter, content_fetcher, document_processor)
   - Each with own status and document counts

3. **documents table**
   - New documents created by Source Hunter
   - content_text populated by Content Fetcher
   - embedding generated by Document Processor
   - Linking tables populated (document_brands, document_segments, etc.)

---

## ğŸ” Troubleshooting

### Error: "Ğ’Ñ‹Ğ¿Ğ°Ğ´Ğ°ÑÑ‰Ğ¸Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹"

**Cause:** No monitoring_profiles in database

**Solution:**
1. Open Supabase Dashboard â†’ SQL Editor
2. Run the SQL from "Create Monitoring Profile" section above
3. Refresh the Admin Panel in browser

### Error: "Missing required parameter: prompt"

**Cause:** Monitoring profile has no prompt_template_id

**Solution:**
1. Verify prompt_templates table has records:
   ```sql
   SELECT id, name, stage FROM public.prompt_templates;
   ```
2. If empty, run Migration 018 manually
3. Update monitoring profile with prompt_template_id:
   ```sql
   UPDATE public.monitoring_profiles
   SET prompt_template_id = (SELECT id FROM public.prompt_templates LIMIT 1)
   WHERE prompt_template_id IS NULL;
   ```

### Error: "No documents created by Source Hunter"

**Cause:** No active sources in database

**Solution:**
1. Check sources:
   ```sql
   SELECT COUNT(*) FROM public.sources WHERE is_active = true;
   ```
2. If 0, run Migration 006:
   ```sql
   UPDATE public.sources SET is_active = true;
   ```

### Error: "Failed to load monitoring profile"

**Cause:** Missing migrations

**Solution:**
1. Check which migrations are applied:
   ```sql
   SELECT * FROM public.schema_migrations ORDER BY version;
   ```
2. Apply missing migrations manually in SQL Editor
3. Ensure Migrations 017-018 are applied

### Frontend shows error in console

**Solution:**
1. Open browser DevTools (F12)
2. Check Console tab for error messages
3. Check Supabase Functions logs:
   - Supabase Dashboard â†’ Functions
   - Click on each function (source-hunter, content-fetcher, document-processor)
   - View execution logs

---

## ğŸ“Š Expected Pipeline Behavior

### Source Hunter Stage (1-2 seconds)
- Loads monitoring_profile
- Loads prompt_template
- Loads active sources
- Generates search queries via OpenAI
- Creates documents in DB (MOCK search results)
- Returns document_ids

**Success indicators:**
- Status: "success"
- documents_created: > 0
- No error_message

### Content Fetcher Stage (2-5 seconds)
- Gets document_ids from Source Hunter
- Fetches content from each URL (with retry logic)
- Parses HTML, extracts text
- Updates documents.content_text
- Updates fetched_at timestamp

**Success indicators:**
- Status: "success"
- documents_updated: > 0
- No error_message

### Document Processor Stage (5-15 seconds)
- Gets document_ids
- Calls GPT-4o for classification
  - Segment classification
  - Brand mentions extraction
  - Geography mentions extraction
  - Event type classification
- Creates linking table entries
- Generates embeddings via OpenAI
- Updates documents with embedding and canonical content

**Success indicators:**
- Status: "success"
- documents_processed: > 0
- linking tables populated (document_brands, document_segments, etc.)
- No error_message

### Final Result
- search_run.status = "completed"
- search_run.execution_time_ms = duration in milliseconds
- search_run.documents_created = number of documents
- All stages logged in search_runs_stages with timestamps

---

## ğŸ¯ Next Steps After Successful Execution

1. **Part 5:** Implement Dedup Agent + Criticality Scorer
   - Dedup: Find duplicate documents via cosine similarity
   - Criticality: Score importance 1-5

2. **Part 6:** Implement Event Extractor Agent
   - Extract 0-N events per document
   - Link to events table

3. **Part 7:** Implement Monitoring Profiles + Prompt Templates UI
   - Create/edit monitoring profiles
   - Manage prompt templates

4. **Phase 5:** Advanced Features
   - CRON scheduling
   - Parallel execution
   - Alert Manager (Telegram/Email)

---

## ğŸ“ Log Viewing & Analysis

### In AdminPanel:
1. Go to **"ğŸ“‹ Ğ›Ğ¾Ğ³Ğ¸ Pipeline"** tab
2. See summary statistics at top
3. Expandable rows show stage-by-stage timeline
4. Click "Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸" to see full run information
5. Click stage name to see its progress

### Interpreting Results:

**Status Badges:**
- ğŸŸ¢ Completed (success)
- ğŸ”´ Failed (error)
- ğŸŸ¡ Running (in progress)

**Duration:** Shows execution time
- Format: Xs (seconds) or Xms (milliseconds)

**Documents:** Shows count of created/processed documents

**Error Messages:** Red text showing what went wrong (if any)

---

## ğŸ”§ Performance Metrics

Typical execution times (approximate):
- Source Hunter: 1-3 seconds
- Content Fetcher: 3-10 seconds (depends on URL count)
- Document Processor: 5-30 seconds (depends on GPT-4o latency)
- **Total:** 9-43 seconds per run

Cost per run (approximate):
- Source Hunter: ~$0.01 (gpt-4o-mini)
- Content Fetcher: ~$0.00 (no API calls)
- Document Processor: ~$0.10-0.50 (gpt-4o)
- Embeddings: ~$0.005 per document
- **Total:** ~$0.11-0.56 per run

---

**Version:** 1.0.0
**Last Updated:** 2025-12-14
**Status:** Production Ready for Testing
